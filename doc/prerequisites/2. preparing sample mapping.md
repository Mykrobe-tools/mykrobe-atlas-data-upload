The Atlas API have endpoint to upload sample metadata and drug resistance prediction results.
These are not in the scope of this documentation. By uploading metadata to the Atlas API, a
sample is created in the Tracking API with the sample id we are uploading as `isolate_id`,
the id generated by the MongoDB as `experiment_id`. The Tracking API is going to issue a new
UUID to uniquely identify the sample throughout Atlas system.

There are two ways to create a file that contains the mapping among the `isolate_id`,
`experiment_id` and the UUID:

- through requesting from Tracking API
- through querying Tracking API db

If you are confident what you are going to do, I will suggest generate the mapping through
querying Tracking API db directly, especially for large number of `included_samples`.

###Requesting from Tracking API

We have created a script for you to create the mapping through requesting from Tracking API
for the `included_samples`. The script is `bin/download_id_mapping_from_tracking_api.py`.

###Querying Tracking API db

The Tracking API db is a Postgres instance hosted on Kubernetes.
```
kubectl exec -ti <tracking-api-db-pod-name> -n <namespace> bash
```

Once you are in the instance, you can use `psql` to fetch the whole `sample` table:
```
psql -U postgres -d postgres
Copy (Select * From sample) To '/tmp/sample.mapping.csv' With CSV DELIMITER ',';
\q
```

You will then need to export the file to where the `included_samples` is stored:
```
KUBECONFIG=<kubeconfig_path> <kubectl_path> cp <namespace>/<tracking-api-db-pod-name>:/tmp/sample.mapping.csv ./sample.mapping.csv
```

The output from the db query can be used to extract mapping for the `included_samples`:
```
python3 bin/extract_included_sample_mapping.py included.samples sample.mapping.csv > included.sample.mapping.csv
```

###Sanity Check
Make sure you have the same number of `included_samples` and the mapping for them.
